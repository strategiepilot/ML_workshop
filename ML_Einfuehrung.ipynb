{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einführung & Grundlagen Machine Learning (ML)  \n",
    "\n",
    "    18. & 19. März 2020, München    \n",
    "    Autor: Andreas Barth, barth@strategiepilot\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Willkommen in **Ihrem persönlichen Jupyter-Notebook**.\n",
    "  \n",
    "Sie können in diesem Notebook alle Beispiele live nachvollziehen, aber auch eigene Varianten ausprobieren.  \n",
    "In der Menüleiste finden sich die wichtigsten Funktionen für \"Maus\"-User.  \n",
    "Hier noch einige sehr hilfreiche Tastatur-Kürzel für effizientes Arbeiten mit der Tastatur:\n",
    "\n",
    "* **Ausführen/Run** einer Zelle mit ... [SHIFT+ENTER]\n",
    "* Eine neue leere Zelle **über** einer Zelle einfügen mit ... [a] \n",
    "* Eine neue leere Zelle **unter** einer Zelle einfügen mit ... [b]\n",
    "* Eine Zelle **löschen/entfernen** !!VORSICHT!! mit ... [dd]\n",
    "* Eine Zelle in **Markdown-Format** umwandeln mit ... [m]\n",
    "* Eine Zelle in **Coding-Format** umwandeln mit ... [y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "a = 3\n",
    "b = 8\n",
    "c = a+b\n",
    "d = a*b\n",
    "e = d/c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "txt = \"Guten Morgen\"\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diesen Code müssen wir am Anfang IMMER ausführen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Grundausstattung an Bibliotheken, die wir immer laden\n",
    "import numpy as np                  # Numerische Operationen, Lineare Algebra\n",
    "from scipy.stats import *           # Funktionsbibliothek mit statistischen Funktionen\n",
    "import matplotlib.pyplot as plt     # Funktionsbilio<thek zur Visualisierung von Daten/Ergebnissen\n",
    "import pandas as pd                 # Bearbeitung von tabellarischen Daten (sog. Data Frames)\n",
    "import seaborn as sns               # Erweiterte Visualisierung von Daten/Ergebnissen etc.\n",
    "import warnings                     # Ermöglicht die Deaktivierung von best. Warnmeldungen\n",
    "import random                       # Damit kann man Zufallszahlen generieren\n",
    "import os                           # Ermöglicht Zugriff auf das Dateiablagesystem \n",
    "import datetime as dt               # Funktionsbiliothek zum Arbeiten mit Zeitreihen Daten\n",
    "import pickle                       # Ermöglicht das Abspeichern von Objekten (z.B. trainierten Modellen)\n",
    "\n",
    "# Ein paar Einstellungen, die einem das Leben einfacher machen\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = [8, 4]\n",
    "from IPython.core.pylabtools import figsize\n",
    "plt.style.use('seaborn-white')\n",
    "# sns.set_style('white')\n",
    "# sns.set_context('talk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(\"F://Data/Data Science Uni/40200/BMW Bank Seminar/Data Sets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "***\n",
    "#  Inhalt\n",
    "\n",
    "2. Daten & Preprocessing\n",
    "   - Daten laden u. explorieren\n",
    "   - Einfaches Preprocessing\n",
    "\n",
    "\n",
    "3. Unsupervised Learning\n",
    "   - Clustering mit Kmeans\n",
    "\n",
    "\n",
    "4. Supervised Learning: Lineare Modelle\n",
    "   - Datenset: BMW Pricing Challenge\n",
    "   - Lineare Regression\n",
    "\n",
    "\n",
    "5. Supervised Learning: Classification\n",
    "   - Datenset: \"Give me some Credit\"\n",
    "   - Ein erstes Modell: Decision Tree\n",
    "   - Modellauswahl & -beurteilung verschiedener Modelle \n",
    "\n",
    "\n",
    "6. Exkurs: NLP Natural Language Processing & Text Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "***\n",
    "## 2. Daten & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### 2.1 Daten laden & explorieren\n",
    "Zunächst schauen wir uns an, wie man Daten in Python gut einlesen, explorieren und für ML vorbereiten kann.  \n",
    "Wenn man mit tabellarischen Daten arbeiten möchte bietet sich insbesondere die Funktionsbibliothek PANDAS an.  \n",
    "Da wir sie bereits standardmässig (s.o. bei imports) aufgerufen haben, steht sie uns sofort zur Verfügung."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "Wir laden ein Datenset mit 261 PKW Modellen, die mit jeweils 8 Merkmalen beschrieben werden.  \n",
    "Im Urzustand sind die Daten so noch nicht in dem Format, dass wir für ML brauchen.  \n",
    "Darum kümmern wir uns jetzt ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cars = pd.read_csv(\"cars.csv\", sep=\",\", decimal=\".\")     # Einlesen der.csv Datei vom Verzeichnis und in den Dataframe \"cars\" schreiben\n",
    "cars.head()                                              # .head()  zeigt die ersten 5 Datensätze/Zeilen des Dataframes an "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Umfang unseres df bestimmen:  Anzahl Datensätze (Zeilen), Anzahl Features (Spalten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anzeigen der Mermale / Features / Spalten, ihrer Datentypen und Anzahl von fehlenden Werten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mittelwerte aller Merkmale ermitteln mit .mean()  \n",
    "Das funktioniert aber auch mit ...    \n",
    ".median()  \n",
    ".std()  \n",
    ".var()  \n",
    ".min()  \n",
    ".max()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cars.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oder wenn man nur die Werte eines bestimmten Merkmals ermitteln möchte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cars.cubicinches.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noch einfacher ... eine komplette Beschreibung der Verteilungsparameter aller numerischen Merkmale unseres Datensets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cars.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "Visuelle Exploration der Daten geht auch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Histogramm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "figsize(20,10)             # stellt die Größe der Abbildung ein (Horizontale, Vertikale)\n",
    "_= cars.hist(bins=30,)     # erzeugt ein Histogramm mit 30er Intervallschritten, einstellbar über bins=xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Countplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualidierung Anzahl Modelle nach \"Country\"\n",
    "figsize(5,2)  \n",
    "_= sns.countplot(x=cars.country, data=cars, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualidierung Boxplot: Verteilung der Kubikinches nach \"Country\"\n",
    "figsize(5,4)  \n",
    "_= sns.boxplot(x=cars.country, y=cars.cubicinches, data=cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Violinplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualidierung Violinplot: Verteilung der Kubikinches nach \"Country\"\n",
    "figsize(5,4)  \n",
    "_= sns.violinplot(x=cars.country, y=cars.cubicinches, data=cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Etwas advancend: Paarweise Verteilung ausgewählter Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "figsize(20,20)\n",
    "_= sns.pairplot(data=cars, vars=[\"mpg\",\"cylinders\",\"hp\",\"time-to-60\"], size=3)  # hue=cars.country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### 2.2 Wichtige Preprocessing Schritte\n",
    "Leider sind Rohdaten in der Realität selten (oder nie) in einem für ML Algorithmen geigneten Zustand,  \n",
    "so dass ein PreProcessing und Vorbereiten der Daten erforderlich ist.\n",
    "Die gängigsten Arbeitsschritte sind ...\n",
    "\n",
    "+ Fehlende Werte ersetzen oder bereinigen\n",
    "+ Kategorielle Daten encoden (umwandeln)\n",
    "+ Numerische Merkmale standardisieren / skalieren\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "#### *Fehlende Werte*\n",
    "... heißen in Python meistens \"NA\" (oder nan). Viele ML Algorithmen funktioneren nicht mit NA Werten im Datenset.  \n",
    "Welche Strategien kann man anwenden?  \n",
    "+ Löschen von einzelnen Datensätzen mit NA Werten\n",
    "+ Löschen von einzelnen Merkmalen (Feature) mit NA Werten\n",
    "+ NA Werte durch Schätzwerte ersetzen => Mittelwert, Median, Modus, Max-Wert, Min-Wert, individueller Wert, Regressionsmodell lernen\n",
    "\n",
    "Wie sieht es in unserem Datenset aus?  \n",
    "Welche Merkmale haben NA und wieviele davon?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cars.isna().sum()\n",
    "# oder prozentual:  \n",
    "# cars.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da uns prozentual nur wenige Werte fehlen, können wir sie bedenkenlos mit dem jeweiligen Mittelwert oder Median des Merkmals ersetzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cars = cars.fillna(cars.mean())   # alternativ mit .median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sind jetzt alle fehlenden Werte ersetzt worden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# OK, dann kümmern wir uns noch um das nicht-numerische Merkaml \"country\"\n",
    "cars.country = cars.country.fillna(\"MISSING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verteilung des Merkmals \"country\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cars.country.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "toc-hr-collapsed": true
   },
   "source": [
    "#### *Kategorielle alphanumerische Daten umwandeln*\n",
    "Sehr viele ML Algorithmen (fast alle in der Bibliothek Scikit-Learn) können nur numerische Daten verarbeiten.  \n",
    "In der Praxis sind kategorielle Merkmale aber häufig alphanumerisch: Farbe, Geschlecht, Hersteller, Modell, Land ...  \n",
    "Wenn man diese Merkmale als Feature nutzen möchte, muss man sie in eine numerische Form encoden:\n",
    "  \n",
    "Zwei gängige Methoden dafür sind \"Label Encoding\" und \"One Hot Encoding\".  \n",
    "\n",
    "OH Encoding hat ggü. Label Encoding einen entscheidenden Vorteil:  \n",
    "Label Encoding stellt eine (häufig nicht real existierende) Logik bzw. Rangfolge zwischen den Merkmalen her:  \n",
    "Label Encoding unseres Merkmals Country führt zu: (0, US), (1, Europe), (2, Japan). Ist Japan > Europe > US ??    \n",
    "Beim OH Encoding hingegen werden die Merkmale transformiert, ohne dass eine ungewollte Rangfolge der Ausprägungen ensteht.\n",
    "\n",
    "Wir transformieren also unser Feature \"colour\" mit dem OH-Encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cars_target = cars.country.copy()          # Brauchen wir später noch ...\n",
    "\n",
    "# Jetzt transformieren wir cars mit \"One Hot Encoding\"\n",
    "cars = pd.get_dummies(cars, )\n",
    "cars.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "#### *Daten normalisieren/standardisieren*\n",
    "Sehr viele Algorithmen nutzen mathematische Distanzmaße wie z.B. den Abstand eines Datenpunktes vom Mittelwert.  \n",
    "Wenn die einzelnen Feature in ihren Ausprägungen unterschiedlich stark skalieren (z.B. Anzahl Zylinder und PS)  \n",
    "dann \"verzerren\" diese unterschiedlichen Skalen die Ergebnisse des Algorithmus.\n",
    "\n",
    "Lösungsstrategie: Einheitliche Skalierung der Daten, d.h. man standardisiert sie.  \n",
    "Schauen wir uns die statistischen Eckwerte (Lageparameter) unserer numerischen Feature an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "feat_num = ['mpg', 'cylinders', 'cubicinches', 'hp', 'weightlbs', 'time-to-60']   # Liste feat_num := Vereinfacht die Adressierung\n",
    "cars.loc[:, feat_num].describe()[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir standardisieren unsere Daten mit der sog. Z-Score Methode (Normalisierung)  \n",
    "Die Funktionsbibliothek Scikit-Learn (ML Methoden) bietet dafür eine geeignete Methode an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler    # importieren des Tools aus scikit-learn\n",
    "\n",
    "X = cars.copy()                        # jetzt wandeln wir unseren Dataframe in eine Datenmatrix X um\n",
    "X = X[feat_num]                        # wir skalieren nur die ersten 6 Feature (nicht das Jahr und die Länder)\n",
    "\n",
    "scaler = StandardScaler().fit(X)       # Trainiert den Scaler auf die Datenmatrix\n",
    "X = scaler.transform(X)                # Transformiert Datenmatrix X\n",
    "\n",
    "print(cars.loc[:0,feat_num])           # Ausgabe der ersten Zeile des Cars Datensets\n",
    "print(X[:1])                           # Ausgabe der ersten Zeile der transformierten Matrix X\n",
    "print(80*\"-\")\n",
    "for i in X[:5]: print(\"\\n\",i)          # Pretty Printing der ersten 5 transformierten Datensätze\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Nach der Exploration und Vorbereitung unserer Daten wenden wir uns jetzt dem ML zu:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 3. Unsupervised Learning: Clustering mit k-Means\n",
    "Wir arbeiten mit unseren cars Daten weiter. Beim **\"unsupervised\" Learning\"** wird ein Modell **ohne ein vorhandenes Label (Lernsignal)** trainiert.  \n",
    "D.h. in unserem Beispiel, dass wir simulieren die Informtion der Herkunft \"country\" nicht zu besitzen.  \n",
    "Dafür erstellen wir eine Datenmatrix X des cars-Datenset OHNE das Feature \"country\".  \n",
    "Wir versuchen das Herkunftsland (Region) über k-Means zu bestimmen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X = cars[feat_num].copy()  # Datenmatrix X mit unseren Features\n",
    "X.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt wenden wir den K-Means Algorithmus an, um die Daten zu clustern.  \n",
    "Bei K-Means muss man die Anzahl der \"vermuteten\" Cluster dem Algorithmus vorgeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X = cars[feat_num].copy()                  # Datenmatrix X mit unseren Features\n",
    "from sklearn.cluster import KMeans         # Import des Algorithmus\n",
    "# X = StandardScaler().fit_transform(X)    # Standardisiert die Datenmatrix - lassen wir erstmal weg\n",
    "km = KMeans(n_clusters=3).fit(X)           # Wendet k-Means auf X an, mit Vorgabe 3 Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mal sehen wie gut k-Means auf unserem Datenset funktioniert.  \n",
    "In realita würden wir natürlich die \"richtige\" Verteilung nicht kennen ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"Gruppierung durch k-Means Algo:\\n\", pd.Series(km.labels_).value_counts())\n",
    "print()\n",
    "print(\"Reale Verteilung im Datenset\\n\", cars_target.value_counts())\n",
    "# km.labels_  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir visualisieren die k-Means Ergebnisse zum besseren Verständnis.  \n",
    "Diese Merkmale stehen uns zur Verfügung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "list(enumerate(cars[feat_num].columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualisierung der Zuordnungen\n",
    "figsize(10,7)\n",
    "\n",
    "# Hier können wir die Merkmale für das Plotting auswählen\n",
    "x,y = 0,2         # x = Merkmal X-Achse, y = Merkmal Y-Achse \n",
    "\n",
    "plt.scatter(X.iloc[:,x], X.iloc[:,y], c=km.labels_,  cmap=\"viridis\")\n",
    "plt.scatter(km.cluster_centers_[:,x], km.cluster_centers_[:,y], c='tomato', marker='*', s=300, ) # Scatterplot mit Centroids\n",
    "plt.title(f\"k-Means Clustering mit Feature {cars.columns[x]} & {cars.columns[y]}\", fontsize=15)\n",
    "plt.xlabel(cars.columns[x]); plt.ylabel(cars.columns[y]); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cars[cars.mpg>35].sort_values(\"mpg\", ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn wir mit der Qualität unseres Modells zufrieden wären (ohne Kenntnis der Echtdaten schwierig!).  \n",
    "Könnten wir es nun verwenden, um weitere NEUE Datensätze zu beurteilen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pkw_new = [\n",
    "    [31.4,4,85,65,2500,19,],\n",
    "    [16,8,304,150,4200,12,],\n",
    "    [24,4,113,95,2000,16,],\n",
    "    [24,4,107,90,2750,15,],\n",
    "    [37.2,4,86,65,2019,16,],\n",
    "    [21.5,4,121,110,2600,13,]] \n",
    "\n",
    "# Wenn wir auf normalisierten Daten trainiert haben, müssen wir die Daten jetzt auch normalisieren:\n",
    "# pkw_new = scaler.transform(pkw_new)\n",
    "\n",
    "km.predict(pkw_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "***\n",
    "## 4. Supervised Learning: Regression\n",
    "Reminder: Supervised Learning, d.h. Modelle werden **immer anhand der vorhandenen Lerninformation (Target Variable)** trainiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### 4.1 Datenset: BMW-PRICING CHALLENGE\n",
    "\n",
    "Dafür bearbeiten wir jetzt ein praxisnäheres Beispiel: Das BMW-Pricing Challenge Datenset auf der Plattform KAGGLE  \n",
    "\n",
    "https://www.kaggle.com/danielkyrka/bmw-pricing-challenge \n",
    "\n",
    "Die Autoren dieses Datensets schreiben dazu:\n",
    "\n",
    "* With this challenge we hope to [...] gain some insight in what the main factors are that drive the value of a used car.  \n",
    "* The data provided consists of almost 5000 real BMW cars that were sold via a b2b auction in 2018.\n",
    "* The price shown in the table is the highest bid that was reached during the auction.\n",
    "* We have also extracted 8 criteria based on the equipment of car that we think might have a good impact on the value of a used car.\n",
    "* These criteria have been labeled feature1 to feature 8 and are shown in the data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Zunächst laden wir die Rohdaten wieder aus unserem Verzeichnis\n",
    "bmw = pd.read_csv(\"bmw_pricing_challenge.csv\")\n",
    "bmw.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "bmw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Summary:*\n",
    "* Keine NA Werte\n",
    "* 5 Kategorielle Merkmale (Datentyp: \"Object\")\n",
    "* 3 Numerische Merkmale (Ganzzahlig: Datentyp \"Integer\")\n",
    "* 2 Merkmale mit Datumsinformationen (im \"falschen\" Datenformat \"Object\")\n",
    "* 8 \"anonyme\" Merkmale mit Datentyp Bool (\"True\" vs. \"False\")\n",
    "\n",
    "Zunächst bearbeiten wir die Datums-Informationen und \"bauen\" daraus weitere Feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Die beiden Datums-Merkmale 'sold_at' und 'registration_date' sollten wir besser in ein Datetime-Format konvertieren\n",
    "bmw.registration_date = pd.to_datetime(bmw.registration_date)\n",
    "bmw.sold_at = pd.to_datetime(bmw.sold_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt können wir das \"Alter\" der Fahrzeuge i.S. der Differenz als zusätzliches Feature einbauen.  \n",
    "Da alle Auktionen aus dem Jahr 2018 sind, spielt das Verkaufsjahr keine Rolle, aber vielleicht der Monat der Auktion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Neue Datums-Features ableiten\n",
    "bmw[\"period\"] = bmw.sold_at - bmw.registration_date   # erstellt Spalte mit Differenz in Tagen\n",
    "bmw[\"period\"] = bmw.period.dt.days                    # normiert die Differenz in Tageseinheiten\n",
    "bmw[\"Sell_Month\"] = bmw.sold_at.dt.month              # Der Monat, in dem die Auktion stattfand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "bmw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Noch ein kurzer Blick auf die Verteilung der numerischen Variablen ...\n",
    "bmw.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schauen wir uns noch kurz die Verteilung des Fahrzeugalters an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Verteilung des Fahrzeugalters (in Jahren) im Datenset:\n",
    "_= (bmw.period/365).hist(bins=70, figsize=(8,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betrachten wir die kategoriellen Features noch etwas genauer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for i in [\"model_key\", \"fuel\", \"paint_color\", \"car_type\"]:\n",
    "    print()\n",
    "    print(f\"Merkmal {i}, Anzahl der Ausprägungen {bmw[i].nunique()}:\\n\")\n",
    "    print(bmw[i].value_counts())\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insbesondere bei den Modellvarianten (Feature 'model_key') gibt es sehr viele Ausprägungen.   \n",
    "Lässt sich das \"vereinfachen\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(8,6)\n",
    "titel = f\"Anteil der 20 häufigst vertretenen Modelle: {bmw.model_key.value_counts(normalize=True)[:20].sum().round(2)}\"\n",
    "_= bmw.model_key.value_counts(normalize=True)[:20].apply(lambda x: x*100).round(2).sort_values(ascending=True).plot(kind=\"barh\", fontsize=12, title=titel)\n",
    "plt.xlabel(\"%\"); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir beschränken unser Modell auf diese 20 am häufigsten vorkommenden Modellreihen.  \n",
    "Dafür erstellen wir ein zweites Datenset \"bmwSmall\" in dem nur noch diese Fahrzeugreihen enthalten sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "t20_models = bmw.model_key.value_counts()[:20].index.to_list()  # Auslesen der T20 Modellbezeichnungen\n",
    "bmwSmall = bmw.loc[bmw.model_key.isin(t20_models),:].copy()     # Neuer DataFrame bmwSmall mit Filterung auf die T20 Modelle\n",
    "print(bmwSmall.shape)                                           # Umfang des neuen DataFrame\n",
    "bmwSmall.model_key.value_counts()                               # In bmwSmall sind nur noch die T20 Modelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und schauen uns die Verteilung der erzielten Auktionspreise je nach Modell an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "bmwSmall.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "figsize(15,10)\n",
    "x,y = bmwSmall.model_key, bmwSmall.price\n",
    "_= sns.boxplot(x, y, data=bmwSmall, color=\"tomato\") # violinplot\n",
    "plt.title(\"Verteilung der Fahrzeugpreise nach Modellreihen\")\n",
    "plt.xticks(fontsize=14, rotation=80); plt.xlabel(\"Modellreihe\"), plt.ylabel(\"Preis\"); plt.ylim(0,70_000); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "bmwByModel = bmwSmall.groupby(\"model_key\")\n",
    "bmwByModel.price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# SavePickle(\"bmwSmall\", bmwSmall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Gepickelten DF einlesen\n",
    "# FILE = \"bmwSmall\"\n",
    "# open_df = open(FILE+'.pickle','rb')\n",
    "# data = pickle.load(open_df)\n",
    "# open_df.close()\n",
    "\n",
    "# bmwSmall = data.copy()\n",
    "# bmwSmall.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### 4.2 Lineare Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt bauen wir unsere Datenmatrix auf, auf der wir dann das Regressionsmodell trainieren wollen.  \n",
    "Die Arbeitspakete:\n",
    "\n",
    "    (1) Datenmatrix und Targetvektor aufbauen: Auswahl der Feature, die wir mit ins Modell nehmen möchten  \n",
    "    (2) NA Werte bereinigen => Es gibt keine in diesem Datenset ... entfällt  \n",
    "    (3) OH-Encoding für die kategoriellen Daten  \n",
    "    (4) Standardisieren der numerischen Daten  \n",
    "  \n",
    "    (5) Trainingsset und Testset trennen  \n",
    "    (6) Lineares Regressionsmodell traineren  \n",
    "    (7) Regressionsmodell visualisieren  \n",
    "\n",
    "##### (1) Datenmatrix & Targetvektor\n",
    "Wir wählen wir aus, welche Features wir in das Modell \"mitnehmen\" möchten: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "features = ['model_key', 'mileage', 'engine_power','fuel', 'paint_color', 'car_type',\n",
    "            'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8',\n",
    "            'period', 'Sell_Month', ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit dieser Auswahl erstellen wir eine Feature-Matrix X und einen Targetvektor y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "bmwSmall.reset_index(inplace=True)   # Numerischen Index neu aufbauen (Lücken aus dem Filterprozess schließen!)\n",
    "X = bmwSmall[features].copy()\n",
    "y = bmwSmall.price.copy()\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (3) & (4) OH-Encoding und Standardisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Wir importieren die Preprocessing Tools aus Scikit-Learn\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler   # Unsere Werkzeuge\n",
    "\n",
    "# Wir legen ein paar Listen an, um das PreProcessing zu erleichtern\n",
    "feat_cat = [\"model_key\", \"fuel\", \"paint_color\", \"car_type\", ] \n",
    "feat_num = ['mileage', 'engine_power', 'period',]\n",
    "feat_bool = ['feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6','feature_7', 'feature_8']\n",
    "feat_other = ['Sell_Month']\n",
    "\n",
    "# Jetzt vereinzeln wir die Matrix X in vier Teil-Matrizen \n",
    "Xcat = X[feat_cat] \n",
    "Xnum = X[feat_num]\n",
    "Xbool = X[feat_bool]\n",
    "Xother = X[feat_other]\n",
    "\n",
    "# OH-Encoding auf der Matrix mit den kategoriellen Daten\n",
    "oh = OneHotEncoder(sparse=False)\n",
    "Xcat = oh.fit_transform(Xcat)\n",
    "Xcat_cols = oh.get_feature_names(feat_cat)\n",
    "Xcat = pd.DataFrame(data=Xcat, columns=Xcat_cols)\n",
    "\n",
    "# # Alternativ: Label-Encoding auf der Matrix mit den kategoriellen Daten\n",
    "# le = LabelEncoder()\n",
    "# Xcat = Xcat.apply(le.fit_transform)\n",
    "# Xcat = pd.DataFrame(data=Xcat, columns=feat_cat)\n",
    "\n",
    "# Standardisieren auf der Matrix mit den numerischen Daten\n",
    "# scaler = StandardScaler()\n",
    "# Xnum = scaler.fit_transform(Xnum)\n",
    "# Xnum = pd.DataFrame(Xnum, columns=feat_num)\n",
    "\n",
    "# Zusammenführen der vier Teilmatrizen zu einer Datenmatrix X\n",
    "X = pd.concat([Xcat, Xnum, Xbool, Xother], axis=1,  )\n",
    "\n",
    "print(f\"Featurematrix X mit {X.shape[0]} Datensätzen und {X.shape[1]} Feature/Variablen\")\n",
    "print(f\"Targetvektor y mit {y.shape[0]} Datensätzen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (5) Trainings- & Testset splitten\n",
    "Wir splitten in ein Trainingsset mit 70% fürs Training und 30% fürs Testen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (6) Lineares Regressionsmodell trainieren "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)  # Model instanziieren und auf die Trainingsdaten trainieren\n",
    "\n",
    "scoreTrain = lr.score(X_train, y_train)        # Ermittelt R² Score für Trainingsdaten\n",
    "scoreTest = lr.score(X_test, y_test)           # Ermittelt den R² für die Testdaten\n",
    "\n",
    "print(\"-\"*65)\n",
    "print(f\"Anteil der erklärbaren Varianz, R² auf dem Trainingsset = {scoreTrain:.2f}\")\n",
    "print(f\"Anteil der erklärbaren Varianz, R² auf den TESTDATEN (!) = {scoreTest:.2f}\")\n",
    "print(\"-\"*65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Ausgabe der einzelnen Faktoren mit ihren Gewichten in der Regression:\n",
    "weights = pd.Series(lr.coef_, index=X.columns.to_list(),)\n",
    "weights.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Mit unserem Modell können wir jetzt den Preis für \"neue\" ungesehene Daten schätzen:  \n",
    "Zur Vereinfachung ziehen wir uns aus unseren \"unberührten\" Testdaten ein Sample und lassen es durch unser Modell schätzen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "Size = 5\n",
    "Sample = X_test.sample(Size, random_state=815)\n",
    "yreal = pd.Series(y_test[Sample.index])\n",
    "ypred = pd.Series(lr.predict(Sample), index=Sample.index, name=\"price_pred\").astype(\"int\")\n",
    "result = pd.concat([ypred,yreal,Sample], axis=1)\n",
    "result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 5 Supervised Learning: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 KAGGLE Competition - \"Give Me Some Credit\"\n",
    "https://www.kaggle.com/c/GiveMeSomeCredit/data\n",
    "\n",
    "Das schreiben die Autoren auf KAGGLE:\n",
    "\n",
    "*Credit scoring algorithms, which make a guess at the probability of default, are the method banks use to determine whether or not a loan should be granted.  \n",
    "This competition requires participants to improve on the state of the art in credit scoring, by predicting the probability that somebody will experience financial distress in the next two years.*\n",
    "\n",
    "*The goal of this competition is to build a model that borrowers can use to help make the best financial decisions.*\n",
    "\n",
    "Hier eine kurze Beschreibung der einzelnen Variablen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "cs_info = pd.read_excel(\"cs-Data Dictionary.xls\", header=1); cs_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Datenset laden\n",
    "cs = pd.read_csv(\"cs-training-small.csv\")\n",
    "cs = cs.iloc[:,1:]\n",
    "cs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt werfen für mal einen Blick auf die Verteilung der Werte der einzelnen Variablen ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cs.describe(percentiles=[.05,.25,.5,.75,.95], ).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sehen an dieser kurzen Statistik bereits, dass in diesem Datenset furchbar große Ausreißer enthalten sind (siehe z.B. RUUL und DebtRation).  \n",
    "Wir wissen nicht, ob diese \"Ausreißer\" wichtig sind für unser Modell ... oder ob es z.B. vernachlässigbare Eingabe-/Übertragungsfehler sind?  \n",
    "Betrachten wir, wieviel Anteil diese speziellen Datensätze an unserer durch das Modell zu prognostizierenden Variable \"SeriousDlqin2yrs\" haben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "csRUUL_o1 = cs.loc[(cs.RevolvingUtilizationOfUnsecuredLines > 1.0),:]  # Auslesen der RUUL auffälligen Datensätze\n",
    "csDebtRatio_o1 =  cs.loc[(cs.DebtRatio > 1.0),:]                       # Auslesen der DebtRatio auffälligen Datensätze\n",
    "RUUL_Defaults = csRUUL_o1.SeriousDlqin2yrs.sum()                       # Anzahl der Defaults in den RUUL auffälligen Datensätzen\n",
    "DebtR_Defaults = csDebtRatio_o1.SeriousDlqin2yrs.sum()                 # Anzahl der Defaults in den DebtRatio auffälligen Datensätzen\n",
    "\n",
    "# Ausgabe der Berechnungen\n",
    "print(f\"Anzahl der 'Defaults' im gesamten Datenset {cs.SeriousDlqin2yrs.sum()}, entspricht {cs.SeriousDlqin2yrs.mean()}\")\n",
    "print(\"-\"*100)\n",
    "print(f\"Anzahl der 'Auffälligen' RUULs Datensätze: {csRUUL_o1.shape[0]}\")\n",
    "print(f\"Anzahl der 'Defaults' in den 'Auffälligen' RUULs Datensätzen {RUUL_Defaults} entspricht {RUUL_Defaults/csRUUL_o1.shape[0]}\")\n",
    "print(\"-\"*100)\n",
    "print(f\"Anzahl der 'Auffälligen' DebtRatio Datensätze: {csDebtRatio_o1.shape[0]}\")\n",
    "print(f\"Anzahl der 'Defaults' in den 'Auffälligen' DebtRatio Datensätzen {DebtR_Defaults} entspricht {DebtR_Defaults/csDebtRatio_o1.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zumindest die RUULs liefern einen überdurchschnittlichen Erklärungsbeitrag für unser Modell.  \n",
    "Wir nehmen die auffälligen Merkmale mit in unsere weiteren Überlegungen.  \n",
    "Jetzt bauen wir unsere Datenmatrix X und unseren Targetvektor y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cs.iloc[:,:-1].copy()\n",
    "y = cs.iloc[:,-1]\n",
    "print(X.shape,y.shape)\n",
    "print(f\"Anteil Defaults im gesamten Datenset {y.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir splitten in ein Trainingsset (2/3) und ein Testset (1/3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33333, shuffle=True, stratify=y, random_state=123)\n",
    "print(f' Trainingsset: {X_train.shape, y_train.shape} / Test Set: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Classification mit Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "model = 'Decision Tree'\n",
    "t_names = ['Kein Default', 'Default']\n",
    "\n",
    "estimator = DecisionTreeClassifier(class_weight=\"balanced\", ) # max_depth=5\n",
    "estimator.fit(X_train, y_train)\n",
    "\n",
    "ytrue = y_test\n",
    "ypred = estimator.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(ytrue, ypred)\n",
    "roc_auc = roc_auc_score(ytrue, ypred)\n",
    "print(f\"Dummy-Baseline Accuracy: {1-y_test.mean()}\")\n",
    "print(f'Accuracy Score: {accuracy:.4f}, AUC: {roc_auc:.4f}')\n",
    "print(\"\\n\",classification_report(ytrue, ypred, target_names=t_names))\n",
    "\n",
    "# Feature Importance aus Model in Dataframe FI schreiben\n",
    "fi_data = {'Feature': list(X_train.columns), 'F_Importance': estimator.feature_importances_}\n",
    "FI = pd.DataFrame(data=fi_data)\n",
    "FI = FI.sort_values('F_Importance', ascending=False); FI\n",
    "\n",
    "# Confusion Matrix erstellen\n",
    "mat = confusion_matrix(ytrue, ypred,)\n",
    "print(\"Confusion Matrix:\\n\",mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit ein paar Optimierungen können wir bereits moderate/gute Ergebnisse erzielen.\n",
    "Nach diesen ersten \"Gehversuchen\" schicken wir ein paar weitere Modelle ins Rennen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Classification mit verschiedenen Modellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beim Decision Tree Classifier ist es nicht notwendig die Daten zu standardisieren.  \n",
    "Bei den Modellen, die wir jetzt zusätzlich ins Spiel bringen, könnte es sehr hilfreich sein.  \n",
    "Wir behalten uns diesen Preprocessing-Schritt noch vor und probieren es zunächst ohne Standardisierung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Standardisieren auf der Matrix mit den numerischen Daten\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir bauen uns ein Pipeline aus verschiedenen Classifiern, die wir in einem \"Durchgang\" auf unsere Trainings- und Testdaten anwenden werden.  \n",
    "Die einzelnen Schritte:\n",
    "\n",
    "+ Importieren der notwendigen Classifier Alogrithmen u. verschd. Werkzeuge.\n",
    "+ Instanziierung der einzelnen Algorithmen (so wird ein konkretes Learner-Objekt daraus).\n",
    "+ Erstellen einer Pipeline (Festlegen, welche Modelle tatsächlich angewendet werden sollen).\n",
    "+ Anlegen eines Dataframe, um die Ergebnisse der einzelnen Modelle abzuspeichern.\n",
    "+ Pipeline-Logik: Ruft die vorab defierten Classifier auf u. wendet sie auf X_train u. X_test an.\n",
    "+ Ausgeben der Ergebnisse aus unserem Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren der Classifier Algorithmen, die wir als Kandidaten verwenden möchten:\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Importieren von Metriken und Zeitfunktionen\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, classification_report\n",
    "import time\n",
    "\n",
    "# Hier sind unsere Classifier Kandidaten Modelle\n",
    "clf1 = GaussianNB()\n",
    "clf2 = SVC(class_weight=\"balanced\",)\n",
    "clf3 = LogisticRegression(class_weight=\"balanced\")\n",
    "clf4 = KNeighborsClassifier()\n",
    "# Dem Random Forest spendieren wir 3 Varianten ...\n",
    "clf5 = RandomForestClassifier(class_weight=\"balanced\", n_jobs=-1)\n",
    "clf6 = RandomForestClassifier(n_estimators = 300, class_weight=\"balanced\", max_depth=3,  bootstrap=True, n_jobs=-1)\n",
    "clf7 = RandomForestClassifier(n_estimators = 500, class_weight=\"balanced\", max_depth=5,  bootstrap=False, n_jobs=-1)\n",
    "\n",
    "# Das ist unsere Pipeline die wir durchlaufen\n",
    "pipeline = [(1, \"NB\",clf1),\n",
    "           (2, \"SVC\", clf2),\n",
    "           (3, \"LogReg\", clf3),\n",
    "           (4, \"Knn5\", clf4),\n",
    "           (5, \"RF\", clf5),\n",
    "           (6, \"RF opt1\", clf6),\n",
    "           (7, \"RF opt2\", clf7),\n",
    "          ]  \n",
    "# Wir speichern die \"Rundenergebnisse\" der einzelnen Classifier in einem Dataframe\n",
    "results = pd.DataFrame( {\"Estimator\":[], \"Accuracy\":[], \"Precision\":[], \"Recall\":[], \"f1\":[], \"AUC\":[], \"Duration\":[]} )\n",
    "models_fitted = []  # Ablegen der gefitteten Modelle (Objekte) in einer Liste\n",
    "\n",
    "# Durchlauf mehrerer Modelle und Wegschreiben des Ergebnisses\n",
    "for i, name, estimator in pipeline:\n",
    "    \n",
    "    # Model fitten u. in Liste ablegen\n",
    "    start = time.time()                     # Stoppuhr: Zwischenzeit nehmen\n",
    "    est = estimator.fit(X_train, y_train)   # model aus Listing nehmen und fitten\n",
    "    models_fitted.append(est)\n",
    "\n",
    "    # Scorings erstellen\n",
    "    ytrue = y_test                          # ...\n",
    "    ypred = est.predict(X_test)             # model auf Testdaten anwenden (predict)\n",
    "    \n",
    "    acc = accuracy_score(ytrue, ypred )     # Accuracy \n",
    "    prec = precision_score(ytrue, ypred )   # Precision \n",
    "    rec = recall_score(ytrue, ypred,  )     # Recall\n",
    "    f1 = f1_score(ytrue, ypred, )           # f1-Score\n",
    "    auc = roc_auc_score(ytrue, ypred, )     # AUC\n",
    "    end = time.time()                       # Stoppuhr: Zwischenzeit nehmen\n",
    "    duration = end - start                  # Walltime in Variable abspeichern\n",
    "    \n",
    "    results.loc[i,:] = [name, acc, prec, rec, f1, auc, duration]\n",
    "    \n",
    "print(f\"Dummy-Baseline Accuracy: {1-y_test.mean()}\")\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_not_normalized.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_not_normalized = results.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exkurs: Textmining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Parking / Backstage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def SavePickle(name, object):\n",
    "    import pickle\n",
    "    save_df = open(str(name)+'.pickle','wb')\n",
    "    pickle.dump(object,save_df)\n",
    "    save_df.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test_total, y_train, y_test_total = train_test_split(X, y, test_size=0.4, shuffle=True, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test_total, y_test_total, test_size=0.5, shuffle=True, stratify=y_test_total, random_state=42)\n",
    "print(f' Trainingsset: {X_train.shape, y_train.shape} / Validation Set: {X_val.shape, y_val.shape}  / Test Set: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Confusion Matix plotten\n",
    "def Plot_confMatrix(y_real, y_pred, title='Titel'):\n",
    "    '''\n",
    "    Erstellen einer Confusion Matrix Grafik\n",
    "    im Abgleich von Label y_real und Prognose y_pred\n",
    "    '''\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    mat = confusion_matrix(y_real, y_pred)\n",
    "    # sns.set(font_scale=1.4)\n",
    "    sns.heatmap(mat, square=True, annot=True,  cmap='Blues', cbar=False, ) #, fmt='d'\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.ylabel('True value')\n",
    "    plt.title(title);\n",
    "    return plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## Schrittweise Selektion von Features\n",
    "\n",
    "results = pd.DataFrame({\"AnzFeature\":[], \"Feature\":[], \"Score\":[]})\n",
    "\n",
    "for i in range(4,len(X_train.columns)):\n",
    "    columns=X_train.columns.to_list()\n",
    "    cs = []\n",
    "    for _ in range(i): \n",
    "        c = max([(lr.fit(X_train[cs+[c]],y_train).score(X_test[cs+[c]],y_test),c) for c in columns])[1]\n",
    "        columns.remove(c)\n",
    "        cs.append(c)\n",
    "    score = lr.score(X_test[cs],y_test).round(5)\n",
    "    results.loc[i,:] = [int(i), cs, score]\n",
    "        \n",
    "#     print(cs)\n",
    "#     score = lr.score(X_test[cs],y_test); score.round(5)\n",
    "\n",
    "results = results.sort_values(by=\"Score\", ascending=False)\n",
    "results[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "category_names = [\"Kein Default\", \"Default\"]\n",
    "sns.heatmap(mat, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "            xticklabels=category_names, yticklabels=category_names)\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\"); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
